# Spark Data Pipeline Example

–ü—Ä–æ—Å—Ç–æ–π ETL-–ø–∞–π–ø–ª–∞–π–Ω –Ω–∞ PySpark —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π.

## –≠—Ç–∞–ø—ã
1. –ß—Ç–µ–Ω–∏–µ CSV
2. –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
3. –ê–≥—Ä–µ–≥–∞—Ü–∏—è: —Å—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ –æ—Ç–¥–µ–ª–∞–º
4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

## –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å

### 1. ETL (PowerShell)
```powershell
docker run -it --rm `
  -v "${PWD}:/work" `
  --entrypoint="" `
  apache/spark `
  /opt/spark/bin/spark-submit `
  /work/src/etl_pipeline.py

![Python](https://img.shields.io/badge/Python-3.8+-blue)
![Spark](https://img.shields.io/badge/Apache_Spark-3.5-red)
![Docker](https://img.shields.io/badge/Docker-yes-blue)

## üìä –ù–æ—É—Ç–±—É–∫
![Jupyter](screenshots/jupyter_screenshot.png)